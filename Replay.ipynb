{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from geodesic_agent import GeodesicAgent\n",
    "from gridworld import Arena, Bottleneck, LinearChamber\n",
    "from graph import CommunityGraph\n",
    "from plot_utils import plot_replay, plot_traj, plot_need_gain\n",
    "from RL_utils import oned_twod\n",
    "\n",
    "def dict_print(d, indent_size=1):\n",
    "    '''\n",
    "        Fancy printing. Collapse identical, consecutive rows in input dictionary d.\n",
    "    '''\n",
    "    indent = ' ' * indent_size\n",
    "    for kdx, key in enumerate(d.keys()):\n",
    "        val = d[key]\n",
    "        if kdx == 0: # No previous one to compare to\n",
    "            prev_val = val\n",
    "            start = kdx\n",
    "            continue\n",
    "        \n",
    "        if val == prev_val: # Consecutive, skip\n",
    "            continue\n",
    "        \n",
    "        # Non-consecutive, print out\n",
    "        if kdx - 1 == start:\n",
    "            print_key = '%d' % start\n",
    "        else:\n",
    "            print_key = '%d-%d' % (start, kdx - 1)\n",
    "        \n",
    "        print(indent + '%s: %s' % (print_key, prev_val))\n",
    "        \n",
    "        # Update\n",
    "        start = kdx\n",
    "        prev_val = val\n",
    "    \n",
    "    if kdx - 1 == start:\n",
    "        print_key = '%d' % start\n",
    "    else:\n",
    "        print_key = '%d-%d' % (start, kdx - 1)\n",
    "\n",
    "    print(indent + '%s: %s' % (print_key, prev_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Open field*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Physics\n",
    "width = 10\n",
    "height = 7\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "one_start_state = np.zeros(num_states)\n",
    "one_start_state[0] = 1\n",
    "all_start_states = np.ones(num_states) / num_states\n",
    "init_state_dist = all_start_states\n",
    "\n",
    "arena = Arena(width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = arena.get_all_transitions()\n",
    "T = arena.transitions\n",
    "\n",
    "## Agent parameters\n",
    "corner_goals = np.array([width - 1, (height - 1) * width, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(0, width * height)\n",
    "goals = all_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 20\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(arena.num_states, arena.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                   s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(arena, np.array(replayed_experiences).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "# params = {'min_need' : 0,\n",
    "#           'max_need' : 1,\n",
    "#           'alpha_fac' : 0.5}\n",
    "\n",
    "# # Plot need, gain, MEVB throughout each of those steps\n",
    "# meta_need = np.mean(needs, axis=1)\n",
    "# meta_gain = np.mean(gains, axis=1)\n",
    "# meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "# verbose = True\n",
    "\n",
    "# for i in range(num_replay_steps):\n",
    "#     print('step %d:' % i)\n",
    "#     if verbose:\n",
    "#         print('\\tReplayed transition:', replayed_experiences[i])\n",
    "#         print('\\tBackup dictionary:')\n",
    "#         dict_print(backups[i], indent_size=8)\n",
    "#         print('\\tReplay history:')\n",
    "#         for j in range(i):\n",
    "#             print('\\t\\t',replayed_experiences[j])\n",
    "\n",
    "#     plot_need_gain(arena, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "#                    meta_gain[i, :], meta_MEVB[i, :], specials=[tuple(replayed_experiences[i])], params=params)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bottleneck chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bottleneck\n",
    "# Store?\n",
    "save = False\n",
    "\n",
    "# Physics\n",
    "room_width = 4\n",
    "corridor_width = 5\n",
    "width = room_width * 2 + corridor_width\n",
    "height = 5\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "valid_states = Bottleneck.get_valid_states(room_width, corridor_width, height)\n",
    "\n",
    "all_states = np.ones(num_states) / len(valid_states)\n",
    "one_state = np.zeros(num_states)\n",
    "one_state[26] = 1\n",
    "init_state_dist = one_state\n",
    "\n",
    "bottleneck = Bottleneck(room_width, corridor_width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = bottleneck.get_all_transitions()\n",
    "T = bottleneck.transitions\n",
    "\n",
    "## Agent parameters\n",
    "corner_goals = np.array([width - 1, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(num_states)\n",
    "goals = corner_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 30\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(bottleneck.num_states, bottleneck.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                  s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds\n",
    "\n",
    "# Save\n",
    "if save:\n",
    "    np.savez('Data/bottleneck_4rw_5cw.npz', replay_seqs=replayed_exps, needs=needs, gains=gains, all_MEVBs=all_MEVBs, backups=backups,\n",
    "                                    room_width=room_width, corridor_width=corridor_width, height=height, num_states=num_states,\n",
    "                                    alpha=alpha, gamma=gamma, num_replay_steps=num_replay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 replay steps\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(bottleneck, np.array(replayed_exps).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.scatter((0.5), (2.485), marker='x', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "# params = {'min_need' : 0,\n",
    "#           'max_need' : 1}\n",
    "\n",
    "# Plot need, gain, MEVB throughout each of those steps\n",
    "# meta_need = np.mean(needs, axis=1)\n",
    "# meta_gain = np.mean(gains, axis=1)\n",
    "# meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "# verbose = True\n",
    "\n",
    "# for i in range(min(num_replay_steps, 50)):\n",
    "#     print('step %d:' % i)\n",
    "#     if verbose:\n",
    "#         print('\\tReplayed transition:', replayed_exps[i])\n",
    "#         print('\\tBackup dictionary:')\n",
    "#         dict_print(backups[i], indent_size=8)\n",
    "#         print('\\tReplay history:')\n",
    "#         for j in range(i):\n",
    "#             print('\\t\\t',replayed_exps[j]) # so dumb\n",
    "\n",
    "#     plot_need_gain(bottleneck, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "#                    meta_gain[i, :], meta_MEVB[i, :], specials=[tuple(replayed_exps[i])], params=params)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Linear chamber\n",
    "# Physics\n",
    "length = 30\n",
    "\n",
    "# Build object\n",
    "init_state_dist = np.ones(length) / length\n",
    "tunnel = LinearChamber(length, init_state_distribution=init_state_dist)\n",
    "all_experiences = tunnel.get_all_transitions()\n",
    "T = tunnel.transitions\n",
    "\n",
    "## Agent parameters\n",
    "goal_states = np.array([length - 1]) # Non-start corners\n",
    "goal_states = np.arange(length)\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 50\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(tunnel.num_states, tunnel.num_actions, goal_states, T, alpha=alpha, gamma=gamma,\n",
    "                  s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(tunnel, np.array(replayed_experiences).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "params = {'min_need' : 0,\n",
    "          'max_need' : 1}\n",
    "\n",
    "# Plot need, gain, MEVB throughout each of those steps\n",
    "# meta_need = np.mean(needs, axis=1)\n",
    "# meta_gain = np.mean(gains, axis=1)\n",
    "# meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "# verbose = True\n",
    "\n",
    "# for i in range(num_replay_steps):\n",
    "#     print('step %d:' % i)\n",
    "#     if verbose:\n",
    "#         print('\\tReplayed transition:', replayed_experiences[i])\n",
    "#         print('\\tBackup dictionary:')\n",
    "#         dict_print(backups[i], indent_size=8)\n",
    "#         print('\\tReplay history:')\n",
    "#         for j in range(i):\n",
    "#             print('\\t\\t',replayed_experiences[j]) # so dumb\n",
    "\n",
    "#     plot_need_gain(tunnel, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "#                    meta_gain[i, :], meta_MEVB[i, :], specials=[tuple(replayed_experiences[i])], params=params)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Community graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-48fbcda6db91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True,\n\u001b[1;32m     36\u001b[0m                                                     check_convergence=check_convergence, convergence_thresh=conv_thresh)\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mneeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_MEVBs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_for_nerds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "## Community graph, a la Anna Schapiro\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(865612)\n",
    "\n",
    "# Store?\n",
    "save = True\n",
    "\n",
    "# Physics\n",
    "num_nbrhds = 3\n",
    "num_nbrs = 5\n",
    "num_states = num_nbrhds * num_nbrs\n",
    "\n",
    "# Build object\n",
    "init_state_dist = np.ones(num_states) / num_states\n",
    "cg = CommunityGraph(num_nbrhds, num_nbrs, init_state_dist)\n",
    "all_experiences = cg.get_all_transitions()\n",
    "T = cg.transitions\n",
    "\n",
    "## Agent parameters\n",
    "goal_states = np.arange(num_states)\n",
    "alpha = 0.3\n",
    "gamma = 0.95\n",
    "num_replay_steps = 200\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(cg.num_states, cg.num_actions, goal_states, T, alpha=alpha, gamma=gamma,\n",
    "                  s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "check_convergence = False\n",
    "conv_thresh = 1e-8\n",
    "replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True,\n",
    "                                                    check_convergence=check_convergence, convergence_thresh=conv_thresh)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds\n",
    "\n",
    "# Save\n",
    "if save:\n",
    "    np.savez('Data/cg_3hd_5rs_lr030.npz', replay_seqs=replayed_exps, needs=needs, gains=gains, all_MEVBs=all_MEVBs, backups=backups,\n",
    "                                    num_nbrhds=num_nbrhds, num_nbrs=num_nbrs, num_states=num_states,\n",
    "                                    alpha=alpha, gamma=gamma, num_replay_steps=num_replay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(replayed_exps[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(replayed_exps.shape)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        print('start: %d, end: %d, GR: %.2f' % (i, j, ga.G[i, 0, j]))\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.imshow(ga.G[:, 0, :])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for s in range(num_states):\n",
    "    print()\n",
    "    for g in range(num_states):\n",
    "        print(s, g, np.max(ga.G[s, :, g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
