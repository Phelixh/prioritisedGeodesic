{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from geodesic_agent import GeodesicAgent\n",
    "from gridworld import Arena, Bottleneck, LinearChamber\n",
    "from graph import CommunityGraph\n",
    "from plot_utils import plot_replay, plot_traj, plot_need_gain\n",
    "from RL_utils import oned_twod\n",
    "\n",
    "def dict_print(d, indent_size=1):\n",
    "    '''\n",
    "        Fancy printing. Collapse identical, consecutive rows in input dictionary d.\n",
    "    '''\n",
    "    indent = ' ' * indent_size\n",
    "    for kdx, key in enumerate(d.keys()):\n",
    "        val = d[key]\n",
    "        if kdx == 0: # No previous one to compare to\n",
    "            prev_val = val\n",
    "            start = kdx\n",
    "            continue\n",
    "        \n",
    "        if val == prev_val: # Consecutive, skip\n",
    "            continue\n",
    "        \n",
    "        # Non-consecutive, print out\n",
    "        if kdx - 1 == start:\n",
    "            print_key = '%d' % start\n",
    "        else:\n",
    "            print_key = '%d-%d' % (start, kdx - 1)\n",
    "        \n",
    "        print(indent + '%s: %s' % (print_key, prev_val))\n",
    "        \n",
    "        # Update\n",
    "        start = kdx\n",
    "        prev_val = val\n",
    "    \n",
    "    if kdx - 1 == start:\n",
    "        print_key = '%d' % start\n",
    "    else:\n",
    "        print_key = '%d-%d' % (start, kdx - 1)\n",
    "\n",
    "    print(indent + '%s: %s' % (print_key, prev_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Open field*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Physics\n",
    "width = 10\n",
    "height = 7\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "one_start_state = np.zeros(num_states)\n",
    "one_start_state[0] = 1\n",
    "all_start_states = np.ones(num_states) / num_states\n",
    "init_state_dist = all_start_states\n",
    "\n",
    "arena = Arena(width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = arena.get_all_transitions()\n",
    "T = arena.transitions\n",
    "\n",
    "## Agent parameters\n",
    "corner_goals = np.array([width - 1, (height - 1) * width, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(0, width * height)\n",
    "goals = all_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 20\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(arena.num_states, arena.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                   s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(arena, np.array(replayed_experiences).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "# params = {'min_need' : 0,\n",
    "#           'max_need' : 1,\n",
    "#           'alpha_fac' : 0.5}\n",
    "\n",
    "# # Plot need, gain, MEVB throughout each of those steps\n",
    "# meta_need = np.mean(needs, axis=1)\n",
    "# meta_gain = np.mean(gains, axis=1)\n",
    "# meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "# verbose = True\n",
    "\n",
    "# for i in range(num_replay_steps):\n",
    "#     print('step %d:' % i)\n",
    "#     if verbose:\n",
    "#         print('\\tReplayed transition:', replayed_experiences[i])\n",
    "#         print('\\tBackup dictionary:')\n",
    "#         dict_print(backups[i], indent_size=8)\n",
    "#         print('\\tReplay history:')\n",
    "#         for j in range(i):\n",
    "#             print('\\t\\t',replayed_experiences[j])\n",
    "\n",
    "#     plot_need_gain(arena, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "#                    meta_gain[i, :], meta_MEVB[i, :], specials=[tuple(replayed_experiences[i])], params=params)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bottleneck chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bottleneck\n",
    "# Store?\n",
    "save = False\n",
    "\n",
    "# Physics\n",
    "room_width = 4\n",
    "corridor_width = 5\n",
    "width = room_width * 2 + corridor_width\n",
    "height = 5\n",
    "num_states = width * height\n",
    "\n",
    "# Build object\n",
    "valid_states = Bottleneck.get_valid_states(room_width, corridor_width, height)\n",
    "\n",
    "all_states = np.ones(num_states) / len(valid_states)\n",
    "one_state = np.zeros(num_states)\n",
    "one_state[26] = 1\n",
    "init_state_dist = one_state\n",
    "\n",
    "bottleneck = Bottleneck(room_width, corridor_width, height, init_state_distribution=init_state_dist)\n",
    "all_experiences = bottleneck.get_all_transitions()\n",
    "T = bottleneck.transitions\n",
    "\n",
    "## Agent parameters\n",
    "corner_goals = np.array([width - 1, height * width - 1]) # Non-start corners\n",
    "all_goals = np.arange(num_states)\n",
    "goals = corner_goals\n",
    "\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 30\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(bottleneck.num_states, bottleneck.num_actions, goals, T, alpha=alpha, gamma=gamma,\n",
    "                  s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds\n",
    "\n",
    "# Save\n",
    "if save:\n",
    "    np.savez('Data/bottleneck_4rw_5cw.npz', replay_seqs=replayed_exps, needs=needs, gains=gains, all_MEVBs=all_MEVBs, backups=backups,\n",
    "                                    room_width=room_width, corridor_width=corridor_width, height=height, num_states=num_states,\n",
    "                                    alpha=alpha, gamma=gamma, num_replay_steps=num_replay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 replay steps\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAFeCAYAAABkX7+OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3ycZZn/8c81SZpTm7aBBmg5N+WcFqFdQQEFQTmIdcFDUVhFRQR1V/z5UpftbzOtB0R31626FFHOVgtS5FRQKli7omBBkHKw0kILpdC0Tdr0kDSTzL1/PBOaptNmMnPP6Xm+79freTWZPHPN3eSZK1eu+557zDmHiIiEW6zYAxARkfxTshcRiQAlexGRCFCyFxGJACV7EZEIULIXEYkAJXsRkTJjZluHex8lexGRCFCyFxEpAjO72Mz+bGbPmNmPzazCzLaa2bfM7K9m9riZ7Zc69zAz+5OZLTWzb2TzeEr2IiIFZmZHAx8F3umcOx7oAz4O1AOPO+emAEuAy1J3mQPMdc5NA97M5jErcx61iEjI2NnNjg3bsw/w1BvPA90DbrnBOXfDgM/fA5wILDUzgFqgDegBHuiPApyV+vidwIWpj28Hrh3ukJTsRUQG27Adll6e/f1j8W7n3NS9nGHArc65f93lRrOvuJ0blvWxa47OaSMztXFERArvEeBDZtYEYGaNZnbIXs5/DJiR+vjj2Tygkr2IyG4MXA7HEJxzLwAzgYfN7FlgEXDAXu7yL8DnzWwpMDqr/5G2OBYR2ZVNneB4Ioc2TmXrU0O0cQpOPXsRkcEcGVXo5URtHBGRCFBlLyKSTsg63Er2IiLphKyNo2QvIpKOKnsRkQgIWWWvCVoRkQhQZS8iMphDbRwRkUhQshcRiYCQ9eyV7EVEdpPZHjflRBO0IiIRoMpeRCQd9exFREIuhBuhKdmLiKQTsspePXsRkQhQZS8iko7aOCIiERCyNo6SvYjIYJqgFRGJiJBV9pqgFRGJAC+VvZk9DYwDVviIN0hz6l/fscst7jtS//7Rc1wov+9FvuLmM3a+fn76Hu8ad71z7m1eoqmNk9Y4Mxs9YsSIek/x3pJIJCpjsVhFRUWF19jlFnfHjh2VgFVVVb3LZ1yAvr4+zIxYLDYhynHzGTuRSAC46urqsrje8hU3n7F7enoagApvAUPWxvGV7FeMGDGivru7e5qneLuYNWtWS2tr67IoxzWzTWY2OpU0vGtqaqKtrS3ycfMZ28y25uM5Uk7XcT5jm9lij9FU2YuIhF4I37xEE7QiIhGgyl5EJB21cUREIiBkbRwlexGRdEJW2atnLyISAarsRUTSURtHRCTktBGaiEhEqLIXEYmAkFX2mqAVEYkAVfYiIumojSMiEnbaCE1EJPxCuBGakr2ISDohq+w1QSsiEgGq7EVE0glZG0eVvYgMyZo7RuclrtFgRmn2S5xlf5QgJXsR2Str7jgR2GjNHV+x5g7fmewV4H4zRnqOmzuXw1GClOxFZCg1wA4gDsy35o4aj7HrgDOBZ8w4zGNcGUTJXkQykQDqgfOBJ625Y4LH2NXAoQQJ/3SPcbPXvxGa2jgiElG1wJHAs9bccZLHuBVAA7DQjH8uiT6+2jgiEnGVQCPwiDV3fMpz7Frg28DtZlR7jj08SvYiIkDQb/+hNXfMteYOn8u464ELgCfM2N9j3OEJWRtH6+xFIsKO3FhNn90BNj2T85vGfIz47R1DnVYH/BMJO9OM5kzH0tT0OeLxvZ5SCxwD7jmLcZJL2opMY0t6quxFoqKq7yRqes8t9jCGpapvFCP6PleUx1YbR0TKknEoRhW1idFuxVgb6rjy/J9PdivGGnAKsHkPUbcDt1LljnYOy/S48srrJzuHAd17ifsCMdZiHJyH78be5dLCURtHRIqsv80yEXjaQ7wu4AtuxdibPcQaaBtwD+Y+jdEBHOU5fmZKNGlnS5W9SHRMTv07Mcc4vUA7cEYeEn0X8K/AJVT3jSR4QVfhK3sIXRtHlb1IdBwBJMkt2XcBK4H3uRVj13oZVaCPoKKf7hyLAayWicAWYKTV9ta5rsrtHh8vclTZi0THgQTP+eOyuG8VQTK+D5jmOdHvAFYBU/oTfcpEwAj694d7fLzMhKxnr2QvEgHW0tYAb71I6ehh3r07dd9W4CK3YuyeJlWzsR34LUGiXzXoaxMJlmDm+tdIdtTGEZEyNJGgBVMFHDKcO7oVY5+y5o593Iqxe1qRk4vDgC3OpU2RLQQ5qoZCJ/v+vXFCRJW9SDQMTJZjraVtxHDunKdEj3N07iHRw85VONXAMfl4/ChRsheJhv6WCAQV/qHFG0rGBq7CKXyyD1kbR8leJBqOI2jhQLDypfA98GGw2t5aYNSAmwq/170maEWkDA2clB1BiSd7gtU3A5dajrPa3sLOMaqyF5EyNHBStpZivSo1cxMJVuH06wYOKtzDh2+7BCV7kZBLTcaOHXRzNmvtC2kiwSqcfr2U/l8jJU3JXiT8DiWYlB2o8C9SGp5jYJc3L6mikMk+lxaO2jgiUiQTCSZlB9rfWtpK+fk/ePVNLcF2D4WjNo6IlJnDCSZlB+qFIr4L1NAGr74xCt16Clllr1fQioTfUexcY9+vh6Di97nHjRdW21sBjEvzpYzfCcuLEq3Qs6XKXiT80lXEFZTuhOeBBL+MBptgtb3hysAFpGQvEn7pkno9MKnQA8lQujkGCFo5+xZsFGrjiEiZWQ6MZOfyy/53EX+zOMMZUjvBtse97DrmTgqVSkO4EZqSvUjIuWVNZwFYS9sHgV+5ZU2NRR7SXrmuymdI9eytttcBz7uuysK/LqBEK/RsqY0jIhIBquxFRNJRG0dEJAJC1sZRshcR2U3pvhI2W76SfXMikdAvjvwa6VzISo2Icc7VF3sMIefvRVclvIQyW+YjgZjZmsrKyuqZM2ee4WFM6UwCXopy3Hg8/gwQa2pq8hn2LY2NjbS3t0c+br5it7W1ASTj8fjxXgMHMrre7v/Laae/tmH/OVe+987JPuNmKaPY19142bOVFb0rPvvJmy8Y6tzZs2cvcs65ZDJ5QK6DsyMPc9zQmn2Ad1/6lHNuaq7j8Mo5l/MBLK6url7qI1a6Ix6Pt0Q9LrDJzHLdi2+PR1NTk+LmObaZdRbzeuO4dR/kuHWu2M+PYY25JuGoSTyX4XNkMbDYy/PtiEMdv7sl+wOezNf3LttDrRcRkXRC1sZRshcRSSdkE7R6UZWISASoshcRSUdtHBGRkNNGaCIiEaHKXkQk7ML3ClpN0IqIRIAqexGRdNTGERGJACV7EZGQ02ocEZGICFllrwlaEZEIUGUvIpKO2jgiIhGgZC8iEgHq2YuISLlRZS8iMlgIl16qshcJCZu29lybtnaeTVurNzb3IZc3oSxBSvYi4fFOYAbwtE1be0ixB1PeUhuhZXuUICV7kXCJAYcDf7Vpa99V7MGUNVX2IlLiKoDRwEM2be3nbdra0iw1paCU7EXCqxa4FrjFpq0dUezBlB21cUSkjNQDHwL+hLnRxR5M2cilhVOibRwtvRQpMTZtbQx4D0E7ZkhvP/TkQ+PT1k4ATtjDKXVACyP6fkBPRiEFSrZCz5aSvUipGdF3NX18g77MEvMrG8dncloVYFT2rc5laEXwVeDvRXnkEq3Qs6VkL1JqKtxRVPAnt2T8OzI5fdasn7S0trYus2lrvwVcvYfTtmH8gQo+7G+g+ee6Kr9X7DGEhXr2IqXnaOAwj/G2A3OAc93S8Vs8xg23kE3QqrIXKT2HAGPstFcr3JKD+3KI44Au4BK3dPzdfoYWIWrjiEi+2GmvVgNjgB7gIGBVlqF6gA7gLLd0/DI/o4sQ7Y0jInl2KEE13gNMzDLGduAvwLFK9NJPyV6ktEwE+ghWz2Sb7G8DTnVLx2/0Nqoo0jp7EcmjiUB16jhymPe9BXjGLR3/S9+Dip7SnWjNlpK9SGk5GqhJfdwynDu6peNfAl7yPqKoKtEKPVtK9iKl5dgBHzcXbRQSuspePXuR0nL4gI/H22mvhivjSNEo2YuUCDvt1Riw/6CbxxVjLJGnjdBEJI/GAwl2Pi+7CSZs24o2oihTG0dE8mQiwfr6fjGyX34puVJlLyJ5MpFdn5P1aJK2eFTZi0ieTCLYe75fjGEuvxTZE1X2IqVjMjC4nBzuC6vEhxJux2RLyV6kdExKc9tBBR+FBNTGEZE8mZDmtjo77dWRBR+JhG6CVslepATYaa+OJf1f2l3s+kIrkayojSNSGpoIiq/NwKgBH9emviYFFb6N0FTZi5QAt+Tg5cA7gOnsfF5OB94DPFKscUVayNo4quxFSoRbcvBSADvt1TXAgW7Jwb8v8pCiK4TvVKVkLyKSTolW6NlSG0dEJAJU2YuIpBOyyl7JXkQkHfXs02pOJBL6xZFfI53LX6nR1pafXXTLLW4+Yzvn6vMSWPr53TQuZJW9+UggZramsrKyeubMmWd4GFM6k8jPe2uWTdx4PL4UqDKzbT7jws4k5Dt2ucXNZ2znXJ2Z9bW2tk4d6tzrn/jAoqSz/a486d7JGYYvm+s4n7Fnz569yDnnksnkAbnGsoMnOb42J/sAXzjvKefckD/rgnLO5XwAi6urq5f6iJXuiMfjLYqbv7jlOOYwfy84dfVrnLralct4SyU2sBhY7CXWQc2OHy3M/oAn8/W9y/ZQ60VEJB317EVEIiBkPXslexGR3WhvHBERKUOq7EVE0lEbR0Qk5LQRmohIRKiyFxGJgJBV9pqgFRGJAFX2IiLpqI0jIhIBIWvjKNmLiAxWwu8lmy0lexGRdEJW2WuCVkQkAlTZi4ikozaOiEjYhW8jNCV7EZF0QlbZl03P3v50Y5X99fpv2eM/3cd77Mdu+pQtudn7Wyrar392oj1y61Xe4y64c7Q9NO87dtedVd5j33Xn123egqO8x7353nPs1nsu8R73Rw8eYj+9b5b94CGvZZhdu6jKfvjgt+y7i/xfb9c88in75qP5egtPkbTKJtkTc5OYsu5qjtqw1v78k5O8xm5uv563vfmI/emnX/cat7FrDie8+V/2xE+W2MJ5Fd7ijui9iCnrvsbE9vV29x2HeIsL0LLuGiave8HuuOujXuNO6LyVt71xm82/60avcesT/8bx6/6dCZ0r7YcPjfIWt8JN4vh1V3P0+rX2nw/n53q7dpHf60386d8ILdujBJVPsgfoNRi1YwRT1v3R/vLjK/wFdlCVhOPWX2NP//h+e/RWvz+tQzedyqGb3rAH5+3nLeaOmGOfrtEc17bS7p1/jre4ALW9xpQ359uv5v+n17gx4MiNn7L7fvGc/eT+am9xEzEYv+UwjtjQZv/zYIu3uG9db2/+0eb8Oj/X25xf32/xxaWZHaLO5XCUoMImezPb6+eZqACq+4yWtuvs+f+Z52lkgaokNLe/n4M6V9vvbh3tLe6IJIzbNo5j216z3/zsVD9BDSod1CUqmPLmg/bgvLifuEFoqpJw9IYv269/9rjdfre/v0qqknBQ57E0t6+3G+9r9hLTAVUOxuyoYfK6v9qPH/DXLnrrelt3nV3/QP6ut1mL/V1v4ocq+yyZxYHvv5Xgg3+/n7p9+KqScET7x2zVfy+3P91Y72uYVCVh/60HcdSGdfb7m0/0F9fByJ4qpryxxB699cve4sYIfpkcu77VHr31t3bXnf6utKokHLrp7Ry2qc3m3T3Ba9yxXaM4rm253XLPB73FrXDBXyWT191mN99znbe4kLreNn7Mbr97uX13UX6ut2886u96k9ypss9CkNjHAP/CzoT//dTnY7Kq8CF4okzYcgSTNrbZEz/1N6lYlYSG7mqmrFtqj930aW9xY0B1Eo5r+0977MYFtnCe38Q8seM9HLx5rS24w9+kYlUSxm1r5Ni21faLu870FrfSQW0ixpR1v7J5d3/HW1wIxnzUxivsjl8+Yz94yN8k9sDr7XsP5+d6u+YRf9ebyACFSfbOOeAqYA5Bgk+m/p0DXJX6enaCKrGOyetesCdv8DepWAHU9BmT1/3UnrzhJm9xIRjzpPYLmND5sj04z9+kYlAl7s/RG9baPfP9TSpWOqjvqeD4NxfZXXde7S1ujGDMx6z/mt19xxL7yf1+20UHd05hYsd6+9GDh3qN23+9ff83ebneOHHNWG9xJXsha+NYLnn2rSBmi6urq+u7u7unDXViEpI1bd8kMa434/hN66BtqKnN/j+feioIms4ZxF3vaBuXwblJgknAZGa/G5s2JGnbN4Nze1OPncjs5Q5N7X20NWaQD5NAn0Fv5rmzqaOPtrEZnO+AHZUZX9BNm3tpG53B/6/PUuPObMxNnQnaGqp2jmlPw+mz1JF5XdO0tYe2kSP2flL/9bajci8PPijuth201WcwL50E/rJ/u7v6zIz+Qps1a1ZLa2vrsowGMQz5ipuv2Ga2GMA59+6cY40/0nH5j7MPED/9Kefc1FzH4VPhXlSVat3EgP/6wm955JRJrNlvzMonjztkyB94zfpEA5srKjii/V17PKk3BmtHvkp77TM4S2YypJqNPQ2sH9HJMRv23DdOxGBr1Q5Wj36UvtiOjOJ27GigrbqTA7aew9ju9M/u/oT8931+Q09lV0ZxN3c3MLqmk9rEMRy45Qiq9vDf7IvB6tHPsrn65UziAtRs7WpgZO3Q34uNtZt4Y+RjJGOJjOJu395AXV0nh3dMp6YvfVbsNdhRkWTl2IfprejOKG73tgZq6jsZ030K47bvu8fvRdJgxdjf01XVkUlcgJqerQ3U1ldw5Mahr7eNdZlfb72dDVQ2DP09Nuc4dn1jpuOVPCnRCj1bhUn2u/bo53zhzsVXfeHOxf2fP8AQrZxZs2a1xM+e0EevPU9lmtMSMfh74zx37OcvZhirzvurC1v3vR5G9+ze203E4I2Rr/F6Q4s7/RObhx33zz/5A2O737l7XIOuqgR/G/ce976L/3fYce//+ecYv/U6BpeUSYIk9MK4We7cj8czjbtL7OU/dHv8Hq8a8zjr605xl1zQN+y4D9/exvit49LG7ajZwitjj3ef/kDGv5zeinvzvTew7/bLdjuhD+ipcLzQ9Al3+ftvzzRuf+x4/clDXG/7zHOfe//Fw43b2tq6zH55596vt323GWYHDie25EGJTrRmqzDJ3jmH2SYG9ujN+l9Zuinrnn0f0FvheH7c590Jl8/1NNpAIgYrGu+no2a6O+MT/n7sPTHYULee1WNa3LkfX+ctbq9Bd2UfL447302f8ZC3uI7gF8iL+/6X+8cZ/89bXAi+x681PMe6kVPdZedn9FdTZnENOqu7WLHP293nz/XXKnjremv6vPuXs/N2vTFu+6teY4tQyDaOc3HM7K3E3p/ws030CYNtI3r4+z6nun+47M/extlfHT/f9HV38qev9RYXgif0K2OXsLH2DHfexzOujjOK2167mVfGTHEXfHS1t7i9Bj0VSV5omuE++qFfeosLwZiX73OTm/Ehv6tPEjFYO+pl1o463n3xnC3+4qaut+X7nuq+8t78XG9fO/NaALt3vrfwkq3SnWjNVmE3Qhuc2LNN9D0xaKt/gzUNLe6kz2z0MTQgeEJ3V/Xy4r7vc6dd+qi3uEmCPvrz477tTv/kv3mLC0FyWz36KdrqT3Yf+khGffSM426q2cbKsVPdxy/8m7e4fQaJmOP5ps+4T3zQ7yqnRAxearyLTTUfcf98jt+/xtrq3+C10S3uq2fl53qbeYa/6038UBuniGIueEK/PPY3dNSe407+tL8fR5/BhvqNrBrd4k7/5Bve4iaBrqokL4z7R/feS+7zFrcyaSRi8OK+P3JnX/xFb3EhqOjXNPyNN0ee4C6+IKPJ44wkgc7qHbzUeLL71PSnvcWtSMKOGDzfdJX77Pn/7S3uwOutvfYc97Wz8nO9tZ7u73oTP/r3xgmR8kn2jo1srN3G6w3fdcd/brbX2B21q2ir38j6+lPcGZ/w117pqlzKupFHs3r0NHfOxRlPPg6pL/YiHTXbWDXmcveBi/y+hH99fTvttQ+6D1zkd4fKzupn6I1N4vWG491l52c82T2kntiTbKybwaox57orz/uDt7hJ28jGuuB6++I5+bve4u/2d72J7EXZJHt30mfWASPZfT1H7rGP+sIR/qOCe9elVwFXcYznuB+c8XtgJJP9xgVwp3zK+5a+AO5DH3lvXuJefv4NwA3e4371rOB6ywP32fPzcr2JZ2rjiIhEgNo4IiIRoMpeRCQCQpbsy+vNS0REJCuq7EVEBtPSSxGRiFCyFxGJAPXsRUSk3KiyFxHZjTZCExGJhpC1cZTsRUQG02ocEZGICFllrwlaEZEIUGUvIpKO2jgiIhEQsjaOkr2ISDqq7EVEQs4RuspeE7QiIhHgq7JvTiQS+ishj8xsOzAiHo9vzUP4kYDF4/EtEY+bz9gjgd7W1tYaz3Flp2av0ULWxjHncv9bxczWVFZWVs+cOfMMD2NKZxLwUpTjxuPxZ4CYmf8LsP8a8B273OLmM3YqbjIejx8/1LnXH3HIoqTZflcuX5XpuwyXzXWcz9izZ89e5JxzyWTygFxjWdPRjg/fln2A6/7hKefc1FzH4ZVzLucDWFxdXb3UR6x0Rzweb4l6XGCTmfV3Er0fTU1Nipvn2GbWmdHP+p5fvMY9v3BhvI7z/BxZDCz2Emvc0Y4rlmZ/wJP5+t5le6hnLyISAeqzi4ikE7LVOEr2IiKDaSM0EZGIUGUvIr7ZvfP3BX4LjAIOTN22EkgA57vpM/K1Kkb2RJW9iOTBSOAooHrAbYcD24D9yd8SSIkIJXuR0vAaUJHm9gpgZYHHIhC6No6WXoqUADd9Rh+wIc2XKoA3CjwcgaCNk+1RgpTsRUrHK2lue9NNnxGyGrMM5PoSuhKkZC9SOl5Ic5taOMWiyl5E8uR5oGfQbc8VYyASPpqgFSkdK4FuYETq8y7gb8UbTsSVaDsmW0r2IqVjJTCwB9CD2jhFUrrtmGwp2YuUjpeBugGfa9llMYWsslfPXqREuOkzuoCBb5pSC6wu0nAkZFTZi5SWV4ExqY/b3fQZgydspRBCuBGaKnuR0rJ8wMeq6otJ6+xFJI+WAX2pj18c7p1t/oIqv8OJMK2zF5E8WglsJ9jtclhr7G3+gi8Br9n8BS35GFjkqLIXkTxaCSQJ1tgPdyXOOGA/4HGbv+BC3wOT8qZkL1JaVhKswun/OBt1wG02f8G3bf4CPcezpTaOiOTRRoLKfiS5rbGvA/4Z+LXNXzDKx8AiRRuhiUg+pXa4fB3Y5qbP2DLU+UOoB04FnrX5CybmPLioUbIXkTxbAazxFKsGOBh42uYvOMtTzGgIWRtHL6oSKTWOFSTtBJu/IKOllwccMrE6Pn/BDoK3NUwnBozCca/9fMF/uI9d+O/exppnNmHLYUCHe33UpmKPpdwp2YuUmkTFLfTZ5QSra4bUZxlXkjH67P8DZZPsCV5r8DvgnMI+bOlW6NlSshcpMe7DH34SyPjFUbNmzWppbW1dZvMXfAu4eg+ndZHkNnorLvcyyMKpBg4qyiOXaO89W+rZi4RbH7AZOJueyl8XezBlo39vnBD17JXsRcKri2Db5CluxoVLij0YKS4le5Fw2gb8Fnibm3GhNlTLhpZeikiJ6wKuBaa7GRduK/ZgylbI2jiaoBUJj15gB/ARN+PCB4o9mLJXohV6tpTsRcLjG8CP3YwL1xZ7IGUvhG9eomQvEhJuxoW9gBK9pKVkLyKSjto4IiIRoDaOiEgEqLIXEQm70l1CmS2tsxcRiQBV9iIig5XwK2GzpWQvIpJOyNo4SvYiIumErLJXz15EJAJU2YuIpKM2johIBISsjaNkLyIymDZCExGJiJBV9pqgFRGJAFX2IiLpqI0jIhIBIWvjKNmLiOwmfBuh+Ur2zYlEQr848mukcyErNSLGOVdf7DGEXLO3SCHcG8d8JBAzW1NZWVk9c+bMMzyMKZ1JwEtRjhuPx58BYk1NTT7DvqWxsZH29vbIx81X7La2NoBkPB4/3mvgQEbX2/1jDzz9ter6OVe+uXyyz7hZyij2db+85NnKir4Vn73g5xcMde7s2bMXOedcMpk8INfB2ajJjqn3ZR9g8WFPOeem5joOr5xzOR/A4urq6qU+YqU74vF4S9TjApvMrL/e8H40NTUpbp5jm1lnMa83brrng9x0jyv282NYYx7f6Rjf+VyGz5HFwGIvz7eRLY53rcr+gCfz9b3L9lDrRUQknZC1cZTsRUTSCdkErV5UJSISAarsRUTSURtHRMqJ3XzvOcDRwKmpz7+c+tL97tLp+VptkzWbsKUeuIydnYdjbcKWLwNbgBvd66OSeR+ENkITkTJ0O9CQ+jgJXANUECx/vKJYg9qLs4DvAAb0EaTeawiS/6PAyoKMImSVvXr2IuG3BqhKHTFgBJAAlhdzUHvxCrCDYJwVBEXpCILk/1rBRuEs+6MEKdmLhN/f0ty2g0JVyMP3MlCX5vZ29/qonkIPJiyU7EXCbxnQO+i2GCWa7N3ro7YAXWm+tLqwA8nhKEFK9iLht5Ldk2cdQbukVKVr17xY0BEo2YtImVlJMDE7UKe7dHq66rlUDJ5PSADPFezRc+nXq2cvIkWyEqgddNurxRjIMCxj119QXRS67aRkLyLlxF06vZ1gCeNA6SZtS8kKYPug20pyjqFcKNmLRMPrAz7uJaicS9lKdv0FVUvBK/scjhKkZC8SDQNfKVv4lsjwrQRqBnzenVqlUzhq44hIGXqWnTWno/STfRvBi6j6rSn4CFTZi0gZeomdPfAaSjzZu9dHOWDtgJv+XqyxhIWSvUg0rGTnC6v6UpO2pa7/F1KS4C+TwunfCE1tHBEpMysJ9saBXSdrh2RzFx5gcxfebHMXjvc9KGvsnmON3afv4cv9k8jbCVbnFJbaOCJShl4n2EwMhv8m4ocDlwDLbO7Ck7yOCj4LPGSN3V+0xu7BJfFygkTfRzHaTqrsRaTcuEunJ4F1BHVnNi2RrUAj8IjNXXipz7EB1QRbGN9mjd3VA25fSfDK2WqKkuxzOEqQkr1IdLxMkIpyecOSOuBHNnfhXJu70Of7YdQDFwBPWGP3/qnb+pdfxgh+UUkOlOxFog2jrKUAAAUsSURBVON5/Ox2WQf8E7DE5i7cJ+dR7Rr3GOA5a+yeSrClQxXwRmp1TgFpbxwRKV/9u0b6aInUAScCz9nchcd5iNevCtgH+D1dVRcB6ym3Fk6JtnH0toQi0bESR4IdFTGbu/DgoU6+oLpxf5u7cDNwwB5OGQHsBzxh3110Gd859Q+ZDuSC9x2zvzV2byZ4J6p06oDrSdKJFXC3y4FKtELPlpK9SFQkeYE+qwJblcnpf6jff+iTgle51lHdext7Tty7x34yo0U9dSRitVQUeI19SCnZi0SE+/T0V9h1C4K9mjVrVktra+sym7vwncBCYHSa03qBTkYkz3PtNY9nHvumIHZjdxe77oEzUBfJiq+R5KZM43pVou2YbCnZi0i2+jdUe5+74ry1Q508DH3ANmC6a69Z7DHu8KiNIyLCNuAB4JPuivO6PcbtJngB2JmuvWaVx7jDF7LKXqtxRGS4uoBW4CLPiX4b8AgwpSQSfciWXqqyF5FMJQkS8gXuivN+6zn2duB7wGzXXhOymro0KNmLSCYagFXAWe6K83yve98OXOTaa+7zHDc3IfuVo2QvIkN5Afh3YI674jzf7xb1r8DDrr3mBc9xc1ei7ZhsKdmLyF65K87rAL6Zl9jtNf+dj7heqLIXEQm70p1ozZZW44iIRIAqexGRwUp4Q7NsKdmLiKQTsjaOkr2ISDohq+zVsxcRiQBV9iIi6aiNIyISASFr4yjZi4gM1r8RWogo2YuIpBOyyl4TtCIiEaDKXkRkN+HbLkHJXkQknZC1cZTsRUTSUWUvIhJyIdwbRxO0IiIRoMpeRCQdtXFERCIgZG0ccy73/5GZrTGzBufcXzyMabDmWCxWmUwm/xbxuKcBeSs1YrEYyWQy8nHzHNsBSzzHLLfrOJ+xjwe2OucOzDWQVZ3gGPuH7AOsr3/KOTc113H45KuyXw9UeIq1G+fjN1L5x+0lSPaP5SF2s3OuAlge8bj5jP0O8vTLusyu43zG3kqQiyQNL8neOfc2H3FEREpGyNo46tmLiAymjdBERCJClb2ISNiFb28cvahKRCQCVNmLiKSjNo6ISASErI2jZC8iMlgIN0JTshcRSSdklb0maEVEIkCVvYhIOmrjiIhEQMjaOEr2IiLphKyyV89eRCQCVNmLiAymjdBERCIiZG0cJXsRkd2EbyM0JXsRkXRCVtlrglZEJAJU2YuIpKM2johIyGkjNBGRiAhZZa+evYhIOi6HIwtm9iUzq8vifp80s/FDnadkLyJSGr4EDCvZm1kF8ElgyGSvNo6ISDp5bOOYWT1wJ3AgUAH8kiBh/87MNjjnTjezucA0oBa4yznXmrrvKuAm4L3A9cBUYJ6ZdQEnO+e60j2mkr2ISDr5naA9G1jrnDsPwMxGA5cCpzvnNqTO+TfnXHuqen/EzCY7555Nfa3bOXdK6r6fAb7inHtybw+oZC8ispunfgO2bw4BasxsYPK9wTl3w4DPlwH/YWbXAg845/7XbLe/JD5iZp8lyNMHAMcA/cn+juEOSMleRGQQ59zZeY7/dzM7ETgXuMbMHh74dTM7DPgKMM0512FmtwA1A07ZNtzH1AStiEiBpVbPbHfO/Qz4D+AEYAswKnVKA0FC32xm+wHn7CXcwPvtkSp7EZHCawG+Z2ZJIAFcAZwMPGRmb6QmaJ8GngdeBh7bS6xbgOuHmqA150L2MjEREdmN2jgiIhGgZC8iEgFK9iIiEaBkLyISAUr2IiIRoGQvIhIBSvYiIhGgZC8iEgH/BybM/mLXq3bOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(bottleneck, np.array(replayed_exps).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.scatter((0.5), (2.485), marker='x', color='r')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "# params = {'min_need' : 0,\n",
    "#           'max_need' : 1}\n",
    "\n",
    "# Plot need, gain, MEVB throughout each of those steps\n",
    "# meta_need = np.mean(needs, axis=1)\n",
    "# meta_gain = np.mean(gains, axis=1)\n",
    "# meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "# verbose = True\n",
    "\n",
    "# for i in range(min(num_replay_steps, 50)):\n",
    "#     print('step %d:' % i)\n",
    "#     if verbose:\n",
    "#         print('\\tReplayed transition:', replayed_exps[i])\n",
    "#         print('\\tBackup dictionary:')\n",
    "#         dict_print(backups[i], indent_size=8)\n",
    "#         print('\\tReplay history:')\n",
    "#         for j in range(i):\n",
    "#             print('\\t\\t',replayed_exps[j]) # so dumb\n",
    "\n",
    "#     plot_need_gain(bottleneck, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "#                    meta_gain[i, :], meta_MEVB[i, :], specials=[tuple(replayed_exps[i])], params=params)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear chamber*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Linear chamber\n",
    "# Physics\n",
    "length = 30\n",
    "\n",
    "# Build object\n",
    "init_state_dist = np.ones(length) / length\n",
    "tunnel = LinearChamber(length, init_state_distribution=init_state_dist)\n",
    "all_experiences = tunnel.get_all_transitions()\n",
    "T = tunnel.transitions\n",
    "\n",
    "## Agent parameters\n",
    "goal_states = np.array([length - 1]) # Non-start corners\n",
    "goal_states = np.arange(length)\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 50\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(tunnel.num_states, tunnel.num_actions, goal_states, T, alpha=alpha, gamma=gamma,\n",
    "                  s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "replayed_experiences, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True)\n",
    "needs, trans_needs, gains, all_MEVBs = stats_for_nerds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the replayed experiences\n",
    "print('First %d replay steps' % num_replay_steps, flush=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "plot_replay(tunnel, np.array(replayed_experiences).astype(int), ax=ax)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Plotting params\n",
    "params = {'min_need' : 0,\n",
    "          'max_need' : 1}\n",
    "\n",
    "# Plot need, gain, MEVB throughout each of those steps\n",
    "# meta_need = np.mean(needs, axis=1)\n",
    "# meta_gain = np.mean(gains, axis=1)\n",
    "# meta_MEVB = np.mean(all_MEVBs, axis=1)\n",
    "# verbose = True\n",
    "\n",
    "# for i in range(num_replay_steps):\n",
    "#     print('step %d:' % i)\n",
    "#     if verbose:\n",
    "#         print('\\tReplayed transition:', replayed_experiences[i])\n",
    "#         print('\\tBackup dictionary:')\n",
    "#         dict_print(backups[i], indent_size=8)\n",
    "#         print('\\tReplay history:')\n",
    "#         for j in range(i):\n",
    "#             print('\\t\\t',replayed_experiences[j]) # so dumb\n",
    "\n",
    "#     plot_need_gain(tunnel, ga.memory, np.average(meta_need[i, :, :], weights=init_state_dist, axis=0), \n",
    "#                    meta_gain[i, :], meta_MEVB[i, :], specials=[tuple(replayed_experiences[i])], params=params)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Community graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Community graph, a la Anna Schapiro\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(865612)\n",
    "\n",
    "# Store?\n",
    "save = True\n",
    "\n",
    "# Physics\n",
    "num_nbrhds = 3\n",
    "num_nbrs = 5\n",
    "num_states = num_nbrhds * num_nbrs\n",
    "\n",
    "# Build object\n",
    "init_state_dist = np.ones(num_states) / num_states\n",
    "cg = CommunityGraph(num_nbrhds, num_nbrs, init_state_dist)\n",
    "all_experiences = cg.get_all_transitions()\n",
    "T = cg.transitions\n",
    "\n",
    "## Agent parameters\n",
    "goal_states = np.arange(num_states)\n",
    "alpha = 1.0\n",
    "gamma = 0.95\n",
    "num_replay_steps = 100\n",
    "\n",
    "# Set up agent\n",
    "ga = GeodesicAgent(cg.num_states, cg.num_actions, goal_states, T, alpha=alpha, gamma=gamma,\n",
    "                  s0_dist=init_state_dist)\n",
    "ga.curr_state = 0\n",
    "ga.remember(all_experiences) # Pre-load our agent with all possible memories\n",
    "\n",
    "## Run replay\n",
    "check_convergence = False\n",
    "conv_thresh = 1e-8\n",
    "replayed_exps, stats_for_nerds, backups = ga.replay(num_steps=num_replay_steps, verbose=True, prospective=True,\n",
    "                                                    check_convergence=check_convergence, convergence_thresh=conv_thresh)\n",
    "needs, gains, all_MEVBs = stats_for_nerds\n",
    "\n",
    "# Save\n",
    "if save:\n",
    "    np.savez('Data/cg_3hd_5rs.npz', replay_seqs=replayed_exps, needs=needs, gains=gains, all_MEVBs=all_MEVBs, backups=backups,\n",
    "                                    num_nbrhds=num_nbrhds, num_nbrs=num_nbrs, num_states=num_states,\n",
    "                                    alpha=alpha, gamma=gamma, num_replay_steps=num_replay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(replayed_exps[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(replayed_exps.shape)\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        print('start: %d, end: %d, GR: %.2f' % (i, j, ga.G[i, 0, j]))\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.imshow(ga.G[:, 0, :])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for s in range(num_states):\n",
    "    print()\n",
    "    for g in range(num_states):\n",
    "        print(s, g, np.max(ga.G[s, :, g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
